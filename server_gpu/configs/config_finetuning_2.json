{
    "workdir": "/mnt/homeGPU/mcarmona",


    "model_conver": "prueba/microsoft/DialoGPT-medium",
    "model_conver_config": "prueba/microsoft/DialoGPT-medium/config.json",
    "model_conver_tokenizer": "prueba/microsoft/DialoGPT-medium",
    "model_conver_tokenizer_config": "prueba/microsoft/DialoGPT-medium/tokenizer_config.json",


    "data_dir": "server_gpu/datasets/v3/split_0.8_Adulto",
    "train_dataset": "train.csv",
    "validation_dataset": "validation.csv",
    "task": "conversational",
    "max_source_length": 128,
    "max_target_length": 128,
    "n_train": -1,
    "n_val": -1,



    "seed": 0,

    "output_dir": "result_finetuning/v3",
    "overwrite_output_dir": true,
    "resume_from_checkpoint": false,

    "do_train": true,
    "do_eval": false,

    "evaluation_strategy": "epoch",
    "num_train_epochs": 3,
    "log_level": "info",
    "logging_strategy": "epoch",
    "save_strategy": "epoch",


    "per_device_train_batch_size": 8,
    "gradient_accumulation_steps": 1,
    "per_device_eval_batch_size": 8,

    "fp16": false,
    "fp16_opt_level": "O1",
    "half_precision_backend": "auto",

    "dataloader_drop_last": true,

    "do_sample": true,
    "temperature": 1.0,
    "top_p": 1.0,
    "max_time": 3.0,
    "max_length": 128,
    "min_length": 0,
    "use_cache": false
}