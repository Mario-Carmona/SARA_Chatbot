{
    "workdir": "/mnt/homeGPU/mcarmona",


    "model_conver": "microsoft/DialoGPT-large",
    "model_conver_config": "microsoft/DialoGPT-large/config.json",
    "model_conver_tokenizer": "microsoft/DialoGPT-large",
    "model_conver_tokenizer_config": "microsoft/DialoGPT-large/tokenizer_config.json",


    "data_dir": "server_gpu/datasets/v4/split_0.8_adult",
    "train_dataset": "train.csv",
    "validation_dataset": "validation.csv",
    "task": "conversational",
    "max_source_length": 128,
    "max_target_length": 128,
    "n_train": -1,
    "n_val": -1,


    "seed": 0,

    "output_dir": "result_finetuning/v3",
    "overwrite_output_dir": true,
    "resume_from_checkpoint": false,

    "do_train": true,
    "do_eval": false,

    "evaluation_strategy": "epoch",
    "num_train_epochs": 10,
    "log_level": "info",
    "logging_strategy": "epoch",
    "save_strategy": "epoch",

    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,

    "fp16": true,
    "fp16_opt_level": "O2",
    "half_precision_backend": "auto",

    "dataloader_drop_last": true,

    "load_best_model_at_end": true,
    "metric_for_best_model": "eval_acc",
    "greater_is_better": true,


    "do_sample": true,
    "temperature": 1.0,
    "top_p": 1.0,
    "max_time": 3.0,
    "max_length": 128,
    "min_length": 0,
    "use_cache": false
}